{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30vMjCw5sdpS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EnuY50r9sdpX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../derived/final_stats_data.csv\",low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D_hv2FBmsdpX",
    "outputId": "5e968113-bbc1-406b-ad37-4e81945b51a0"
   },
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "etCv955YsdpZ",
    "outputId": "1098ee93-a1dc-4d01-e928-32258c8ab1fd"
   },
   "outputs": [],
   "source": [
    "len(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9YDwL6qsdpa"
   },
   "source": [
    "adding delivery type column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RDywIHq3sdpb",
    "outputId": "fb1c536c-c55b-4fcb-a1b2-ed8d9c7c0106"
   },
   "outputs": [],
   "source": [
    "df['total_run'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KeVB-Jh-sdpc"
   },
   "outputs": [],
   "source": [
    "df['delivery_type'] = df['total_run'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lHwFmPJHsdpd",
    "outputId": "29f2efa5-c5aa-44e5-c9d0-39e33f87c175"
   },
   "outputs": [],
   "source": [
    "df['delivery_type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pkgI5cwgsdpe",
    "outputId": "b12f369b-5384-4b04-8f5a-6af82a4f183c"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HfjGU9ftsdpf"
   },
   "source": [
    "removing some columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jin3wI0Esdpf"
   },
   "outputs": [],
   "source": [
    "df.drop(['non-striker', 'extra_type',\n",
    "       'non_boundary', 'player_out', 'kind',\n",
    "       'fielders_involved', 'City','MatchNumber','SuperOver',\n",
    "       'WonBy', 'Margin', 'method','Player_of_Match',\n",
    "       'Team1Players', 'Team2Players', 'Umpire1', 'Umpire2',\n",
    "       'WinningTeam', 'Team2','Date','Team1','Venue','TossWinner','batter','bowler'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u-6u84p9sdpg",
    "outputId": "e33cadf7-bf35-4b05-cde3-c5b441076014"
   },
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5TvJRRBNsdpg"
   },
   "source": [
    "Encoding some categorical columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RkSDsnVQsdpg"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "columns_to_encode = ['Season', 'BattingTeam', 'BowlingTeam','delivery_type','TossDecision']\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform on the training data\n",
    "encoder.fit(df[columns_to_encode])\n",
    "\n",
    "# Transform the specified categorical columns to one-hot encoded representation\n",
    "one_hot_encoded = encoder.transform(df[columns_to_encode])\n",
    "\n",
    "# Concatenate the one-hot encoded features with the original DataFrame\n",
    "df = pd.concat([df, pd.DataFrame(one_hot_encoded, columns=encoder.get_feature_names_out(columns_to_encode))], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "df = df.drop(columns_to_encode, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e1u78PMYsdph"
   },
   "source": [
    "scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxYsBHfLsdph",
    "outputId": "3357c4f1-dcc0-4ef5-bba0-16dde5c29f30"
   },
   "outputs": [],
   "source": [
    "df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3LyKReZ4sdph"
   },
   "outputs": [],
   "source": [
    "# Specify the columns to scale\n",
    "columns_to_scale = ['strike_rate_x', 'batting_average', 'strike_rate_y', 'bowling_average',\n",
    "                    'economy','runs_conceded','runs_scored','balls_faced','balls_bowled',\n",
    "                    'batter_matches_played','0s_scored', '1s_scored', '2s_scored', '4s_scored', '6s_scored',\n",
    "                     'high_score', '25_scored', '50_scored', '75_scored', '100_scored','0_wickets_taken', '1_wickets_taken',\n",
    "                    '2_wickets_taken', '3_wickets_taken', '4_wickets_taken', '5_wickets_taken','6_wickets_taken',\n",
    "                    'bowler_matches_played','wickets_taken','4s_conceded','6s_conceded', '0s_conceded', '1s_conceded',\n",
    "                    '2s_conceded', 'highest_conceded',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qOrWJe0usdpi",
    "outputId": "62acda53-12a6-4a35-a0a7-42af6978848f"
   },
   "outputs": [],
   "source": [
    "print(df[columns_to_scale].max())\n",
    "print(df[columns_to_scale].min())\n",
    "print(df[columns_to_scale].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cIGxJ5Zsdpi"
   },
   "outputs": [],
   "source": [
    "# Replace infinite or too large values with the median\n",
    "df[columns_to_scale] = df[columns_to_scale].replace([np.inf, -np.inf], np.nan)\n",
    "df[columns_to_scale] = df[columns_to_scale].fillna(df[columns_to_scale].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDkddarAsdpi"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the selected columns\n",
    "df[columns_to_scale] = scaler.fit_transform(df[columns_to_scale])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ltp9FLwwsdpi"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "id": "R4hwMrr4sdpi",
    "outputId": "bee1a7ea-bac7-42a5-e38c-95684074357f"
   },
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "I58NHGdosdpj",
    "outputId": "e4d6bf54-e270-492b-b507-334a7af56dd2"
   },
   "outputs": [],
   "source": [
    "df[columns_to_scale].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KgOHV4Vnsdpj",
    "outputId": "18fffb80-09e9-4b31-f38f-c426a9e197fa"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G99uplOKsdpj"
   },
   "source": [
    "fixed length sequence creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E5wKLp1Lsdpk"
   },
   "outputs": [],
   "source": [
    "feature_columns = ['innings', 'overs', 'ballnumber', \n",
    " 'isWicketDelivery', 'batter_matches_played', 'runs_scored', 'dismissals', 'balls_faced', '0s_scored',\n",
    " '1s_scored', '2s_scored', '4s_scored', '6s_scored', 'high_score', '25_scored', '50_scored', '75_scored',\n",
    " '100_scored', 'strike_rate_x', 'batting_average', 'notout', 'explosivity_rating', '0_wickets_taken', '1_wickets_taken',\n",
    " '2_wickets_taken', '3_wickets_taken', '4_wickets_taken', '5_wickets_taken', '6_wickets_taken',\n",
    " 'bowler_matches_played', 'runs_conceded', 'extras_runs_conceded', 'wickets_taken', 'balls_bowled',\n",
    " '4s_conceded', '6s_conceded', '0s_conceded', '1s_conceded', '2s_conceded', 'highest_conceded',\n",
    " 'strike_rate_y', 'bowling_average', 'economy', 'total_runs_conceded', 'target', 'current_score', 'balls_left',\n",
    " 'wickets_left', 'runs_left', 'Season_2008', 'Season_2009', 'Season_2010', 'Season_2011',\n",
    " 'Season_2012', 'Season_2013', 'Season_2014', 'Season_2015', 'Season_2016', 'Season_2017',\n",
    " 'Season_2018', 'Season_2019', 'Season_2020', 'Season_2021', 'Season_2022', 'BattingTeam_Chennai Super Kings',\n",
    " 'BattingTeam_Deccan Chargers', 'BattingTeam_Delhi Capitals', 'BattingTeam_Gujarat Lions', 'BattingTeam_Gujarat Titans',\n",
    " 'BattingTeam_Kochi Tuskers Kerala', 'BattingTeam_Kolkata Knight Riders', 'BattingTeam_Lucknow Super Giants',\n",
    " 'BattingTeam_Mumbai Indians', 'BattingTeam_Pune Warriors', 'BattingTeam_Punjab Kings',\n",
    " 'BattingTeam_Rajasthan Royals', 'BattingTeam_Rising Pune Supergiant',\n",
    " 'BattingTeam_Royal Challengers Bangalore', 'BattingTeam_Sunrisers Hyderabad',\n",
    " 'BowlingTeam_Chennai Super Kings', 'BowlingTeam_Deccan Chargers',\n",
    " 'BowlingTeam_Delhi Capitals', 'BowlingTeam_Gujarat Lions',\n",
    " 'BowlingTeam_Gujarat Titans', 'BowlingTeam_Kochi Tuskers Kerala',\n",
    " 'BowlingTeam_Kolkata Knight Riders', 'BowlingTeam_Lucknow Super Giants',\n",
    " 'BowlingTeam_Mumbai Indians', 'BowlingTeam_Pune Warriors',\n",
    " 'BowlingTeam_Punjab Kings', 'BowlingTeam_Rajasthan Royals',\n",
    " 'BowlingTeam_Rising Pune Supergiant', 'BowlingTeam_Royal Challengers Bangalore',\n",
    " 'BowlingTeam_Sunrisers Hyderabad', 'delivery_type_0',\n",
    " 'delivery_type_1', 'delivery_type_2', 'delivery_type_3', 'delivery_type_4', 'delivery_type_5',\n",
    " 'delivery_type_6', 'delivery_type_7', 'TossDecision_bat', 'TossDecision_field']\n",
    "#'batsman_run', 'extras_run', 'total_run' removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "KkGlEg_Hsdpk"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "sequence_length = 6\n",
    "\n",
    "def create_sequences(group):\n",
    "    sequences = []\n",
    "    for inning in group['innings'].unique():\n",
    "        inning_data = group[group['innings'] == inning]\n",
    "\n",
    "\n",
    "        features = inning_data[feature_columns]\n",
    "\n",
    "        for i in range(len(inning_data) - sequence_length + 1):\n",
    "            sequence = features.iloc[i:i + sequence_length].copy()\n",
    "\n",
    "            sequences.append(sequence)\n",
    "    return sequences\n",
    "\n",
    "# Group by the relevant columns (including one-hot encoded columns)\n",
    "grouped_df = df.groupby(['ID']).apply(create_sequences)\n",
    "sequences = [item for sublist in grouped_df for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7JvJh_Wssdpl",
    "outputId": "65908640-cee8-46cd-ebf5-973bb8c71077"
   },
   "outputs": [],
   "source": [
    "(df.isna().sum()==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "id": "qY9nr3Vfsdpl",
    "outputId": "80ae93e9-fd9c-4068-8d25-cb26a2c3c6fa"
   },
   "outputs": [],
   "source": [
    "sequences[0] #222521-222526 #checks only after 6 run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "A2wZv0zq9urQ",
    "outputId": "9c8c5d85-f76c-46f9-ae09-aed397f7dce3"
   },
   "outputs": [],
   "source": [
    "len(sequences[0].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMJoCipLsdpl"
   },
   "source": [
    "check if each sequence have the same columsn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "7X-YR6l3sdpl"
   },
   "outputs": [],
   "source": [
    "# Get a list of all unique columns across all sequences\n",
    "all_columns = set()\n",
    "for sequence in sequences:\n",
    "    all_columns.update(sequence.columns)\n",
    "\n",
    "# Ensure all sequences have the same columns\n",
    "for i, sequence in enumerate(sequences):\n",
    "    missing_columns = list(all_columns - set(sequence.columns))\n",
    "    if missing_columns:\n",
    "        # Add missing columns with NaN values\n",
    "        sequences[i] = pd.concat([sequence, pd.DataFrame(columns=missing_columns)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rdkp_sQp9_yI"
   },
   "outputs": [],
   "source": [
    "sequences[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7D5xpNoQsdpm"
   },
   "source": [
    "sequences into 3D numpy array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RLAcCAjqsdpm"
   },
   "source": [
    "Extract the target column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1bahGqPUsdpm"
   },
   "outputs": [],
   "source": [
    "target_columns = [f'delivery_type_{i}' for i in range(8)]\n",
    "target = np.array([sequence[target_columns].values[-1] for sequence in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xW9rtWP8AaJN",
    "outputId": "fb737dbf-3b21-4b11-e640-be37f6765929"
   },
   "outputs": [],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dulGphKu-2D3"
   },
   "outputs": [],
   "source": [
    "#drop the labels from data\n",
    "columns_to_drop = ['delivery_type_0', 'delivery_type_1', 'delivery_type_2', 'delivery_type_3',\n",
    "                           'delivery_type_4', 'delivery_type_5', 'delivery_type_6', 'delivery_type_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rqh9hju-_01N"
   },
   "outputs": [],
   "source": [
    "all_columns = [col for col in all_columns if col not in columns_to_drop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Iv2Ac5q8_vhP"
   },
   "outputs": [],
   "source": [
    "data = np.array([sequence[list(all_columns)].values for sequence in sequences]) #runs slow ~ 2mins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 176
    },
    "id": "CCqUdARWvbiY",
    "outputId": "a79e182d-bfe9-4a14-8bec-315a74d3c875"
   },
   "outputs": [],
   "source": [
    "data.shape, target.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rugBT9_csdpn"
   },
   "source": [
    "split dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfGA-nRMsdpn"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dxqAdc7Tsdp0"
   },
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=42)\n",
    "\n",
    "inf_indices = np.where(np.isinf(X_train))\n",
    "\n",
    "inf_rows = inf_indices[0]\n",
    "inf_cols = inf_indices[1]\n",
    "\n",
    "# Remove rows with infinity values\n",
    "X_train_cleaned = np.delete(X_train, inf_rows, axis=0)\n",
    "y_train_cleaned = np.delete(y_train, inf_rows, axis=0)\n",
    "\n",
    "inf_indices = np.where(np.isinf(X_test))\n",
    "\n",
    "inf_rows = inf_indices[0]\n",
    "inf_cols = inf_indices[1]\n",
    "\n",
    "# Remove rows with infinity values\n",
    "X_test_cleaned = np.delete(X_test, inf_rows, axis=0)\n",
    "y_test_cleaned = np.delete(y_test, inf_rows, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTju8LJw0WeV",
    "outputId": "f361abde-adb1-4fcd-d4e6-5adf19d48c08"
   },
   "outputs": [],
   "source": [
    "X_train_cleaned.shape, y_train_cleaned.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_cleaned.shape, y_test_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RVxWG3C-sdp1"
   },
   "source": [
    "Dataset and dataloader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eDEnfIEGsdp1"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOF7_iV3sdp1"
   },
   "outputs": [],
   "source": [
    "class CricketDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, sequences, targets):\n",
    "        # Convert sequences to a compatible numeric type (float32)\n",
    "        self.sequences = torch.tensor(sequences, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.sequences[index], self.targets[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BYn78VzVsdp2"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataset = CricketDataset(X_train_cleaned, y_train_cleaned)\n",
    "test_dataset = CricketDataset(X_test_cleaned, y_test_cleaned)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3kQ-QvwNsdp2",
    "outputId": "f2cde8bb-4ced-4acd-a749-27760de8ab52"
   },
   "outputs": [],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Mskkw65sdp2"
   },
   "source": [
    "Lstm class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-i9k78Jsdp2"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yCztHIgXsdp3"
   },
   "outputs": [],
   "source": [
    "class MyLSTMWithSoftmax(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyLSTMWithSoftmax, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :] # Extract the output of the last time step\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = F.softmax(out, dim=1)  # Apply softmax activation\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyLSTMWithWickets(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(MyLSTMWithWickets, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 32)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(32, output_size)  # Output layer for delivery type prediction\n",
    "        self.fc3 = nn.Linear(32, 1)            # Output layer for wicket prediction\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]  # Extract the output of the last time step\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        delivery_type_out = self.fc2(out)  # Output for delivery type prediction\n",
    "        wicket_out = self.fc3(out)         # Output for wicket prediction\n",
    "        return delivery_type_out, torch.sigmoid(wicket_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PuZklCvosdp3"
   },
   "outputs": [],
   "source": [
    "input_size = data.shape[2] #96 expected\n",
    "hidden_size = 64\n",
    "output_size = 8\n",
    "\n",
    "model = MyLSTMWithSoftmax(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TMbqaH2H1ucC"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kQanvWvJ1zfO",
    "outputId": "3a5adace-3b34-4f99-83f5-c8dee6b8dbe4"
   },
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KiEedJvZ15p_"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uWywl6CKsdp3",
    "outputId": "af26eca4-c805-4cb9-c4c2-6aae3144b298"
   },
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Inside the training loop\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "\n",
    "        # Assuming 'inputs' and 'labels' are torch Tensors\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert labels to long data type\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #uopdate weights\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the loss at the end of each epoch (optional)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UTpQeGJH4M0_",
    "outputId": "ad14b49f-4b86-4884-f1b7-45433076522c"
   },
   "outputs": [],
   "source": [
    "for data, label in test_loader:\n",
    "    print(data.shape, label.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WoNery0W44fp"
   },
   "outputs": [],
   "source": [
    "torch.set_printoptions(precision=4, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RHenX-phsdp4",
    "outputId": "a2e29f67-954c-4bc6-c2ed-49fb610445c8"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        out = model(inputs)\n",
    "        y_pred = F.softmax(out, dim=1)\n",
    "        # print(y_pred[0])\n",
    "        # print(labels[0])\n",
    "        our_predictions = torch.argmax(y_pred, dim=1)\n",
    "        actual_predictions = torch.argmax(labels, dim=1)\n",
    "        # print(our_predictions[0:10], actual_predictions[0:10])\n",
    "        # assert(False)\n",
    "\n",
    "        correct_predictions += torch.sum(our_predictions == actual_predictions)\n",
    "        total_samples += batch_size\n",
    "\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f'Accuracy: {accuracy*100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pFvEuIl_6il8",
    "outputId": "342f94e0-efb8-4298-fe38-b6cf4429a6ac"
   },
   "outputs": [],
   "source": [
    "for data, label in test_loader:\n",
    "  print(data, label)\n",
    "  break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gpu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 90\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.\n",
    "\n",
    "    # Inside the training loop\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "        # Assuming 'inputs' and 'labels' are torch Tensors\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Convert labels to long data type\n",
    "        labels = labels.float()\n",
    "\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        #uopdate weights\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Print the loss at the end of each epoch (optional)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs,labels = inputs.to(device),labels.to(device)\n",
    "        out = model(inputs)\n",
    "        y_pred = F.softmax(out, dim=1)\n",
    "        # print(y_pred[0])\n",
    "        # print(labels[0])\n",
    "        our_predictions = torch.argmax(y_pred, dim=1)\n",
    "        actual_predictions = torch.argmax(labels, dim=1)\n",
    "        # print(our_predictions[0:10], actual_predictions[0:10])\n",
    "        # assert(False)\n",
    "\n",
    "        correct_predictions += torch.sum(our_predictions == actual_predictions)\n",
    "        total_samples += batch_size\n",
    "\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f'Accuracy: {accuracy*100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GQFJijbg8qdV"
   },
   "source": [
    "# Model training done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saving the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'model' is your PyTorch model\n",
    "torch.save(model.state_dict(), '../model/cric_model_2nd.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model saved\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# simualte match\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyLSTMWithSoftmax(99, 64, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('../model/cric_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ljgcBnzm8roO"
   },
   "outputs": [],
   "source": [
    "unique_matches = len(set(df['ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "BGrtKp0J8sGl",
    "outputId": "56970ee0-651a-491b-b6de-5bf4e4f692e4"
   },
   "outputs": [],
   "source": [
    "df.head() # is our main DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NPikJ1IC8vSE"
   },
   "outputs": [],
   "source": [
    "unique_ids = df['ID'].unique()\n",
    "\n",
    "id_dataframes = {}\n",
    "\n",
    "for unique_id in unique_ids:\n",
    "    id_dataframes[unique_id] = df[df['ID'] == unique_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VkBOPDN89sN",
    "outputId": "6b4ec989-fdbe-49f7-dd91-3d1f9098c73a"
   },
   "outputs": [],
   "source": [
    "unique_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261
    },
    "id": "-VCzC31m8_V9",
    "outputId": "a2f68f8d-32f6-4064-cedf-cfe3890f0f90"
   },
   "outputs": [],
   "source": [
    "id_dataframes[unique_ids[0]].iloc[:6].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avy4v4X_9Gi8"
   },
   "outputs": [],
   "source": [
    "\n",
    "selected_match_df = id_dataframes[1312200]\n",
    "selected_match_df.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = selected_match_df[['innings', 'overs', 'ballnumber', 'batsman_run', 'extras_run', 'total_run',\n",
    "                               'isWicketDelivery', 'batter_matches_played', 'runs_scored', 'dismissals',\n",
    "                               'balls_faced', '0s_scored', '1s_scored', '2s_scored', '4s_scored', '6s_scored',\n",
    "                               'high_score', '25_scored', '50_scored', '75_scored', '100_scored', 'strike_rate_x',\n",
    "                               'batting_average', 'notout', 'explosivity_rating', '0_wickets_taken', '1_wickets_taken',\n",
    "                               '2_wickets_taken', '3_wickets_taken', '4_wickets_taken', '5_wickets_taken',\n",
    "                               '6_wickets_taken', 'bowler_matches_played', 'runs_conceded', 'extras_runs_conceded',\n",
    "                               'wickets_taken', 'balls_bowled', '4s_conceded', '6s_conceded', '0s_conceded',\n",
    "                               '1s_conceded', '2s_conceded', 'highest_conceded', 'strike_rate_y', 'bowling_average',\n",
    "                               'economy', 'total_runs_conceded', 'target', 'current_score', 'balls_left',\n",
    "                               'wickets_left', 'runs_left', 'Season_2008', 'Season_2009', 'Season_2010', 'Season_2011',\n",
    "                               'Season_2012', 'Season_2013', 'Season_2014', 'Season_2015', 'Season_2016', 'Season_2017',\n",
    "                               'Season_2018', 'Season_2019', 'Season_2020', 'Season_2021', 'Season_2022',\n",
    "                               'BattingTeam_Chennai Super Kings', 'BattingTeam_Deccan Chargers', 'BattingTeam_Delhi Capitals',\n",
    "                               'BattingTeam_Gujarat Lions', 'BattingTeam_Gujarat Titans', 'BattingTeam_Kochi Tuskers Kerala',\n",
    "                               'BattingTeam_Kolkata Knight Riders', 'BattingTeam_Lucknow Super Giants', 'BattingTeam_Mumbai Indians',\n",
    "                               'BattingTeam_Pune Warriors', 'BattingTeam_Punjab Kings', 'BattingTeam_Rajasthan Royals',\n",
    "                               'BattingTeam_Rising Pune Supergiant', 'BattingTeam_Royal Challengers Bangalore',\n",
    "                               'BattingTeam_Sunrisers Hyderabad', 'BowlingTeam_Chennai Super Kings', 'BowlingTeam_Deccan Chargers',\n",
    "                               'BowlingTeam_Delhi Capitals', 'BowlingTeam_Gujarat Lions', 'BowlingTeam_Gujarat Titans',\n",
    "                               'BowlingTeam_Kochi Tuskers Kerala', 'BowlingTeam_Kolkata Knight Riders', 'BowlingTeam_Lucknow Super Giants',\n",
    "                               'BowlingTeam_Mumbai Indians', 'BowlingTeam_Pune Warriors', 'BowlingTeam_Punjab Kings',\n",
    "                               'BowlingTeam_Rajasthan Royals', 'BowlingTeam_Rising Pune Supergiant',\n",
    "                               'BowlingTeam_Royal Challengers Bangalore', 'BowlingTeam_Sunrisers Hyderabad',\n",
    "                               'TossDecision_bat', 'TossDecision_field']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch tensor\n",
    "features_tensor = torch.tensor(features.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tensor = features_tensor.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataLoader with batch size 1\n",
    "single_match_loader = DataLoader(TensorDataset(features_tensor), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping = {0: 'delivery_type_0', 1: 'delivery_type_1', 2: 'delivery_type_2',\n",
    "                 3: 'delivery_type_3',\n",
    "                 4: 'delivery_type_4',5: 'delivery_type_5',\n",
    "                 6: 'delivery_type_6',7: 'delivery_type_7'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in single_match_loader:\n",
    "        print(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in single_match_loader:\n",
    "        # print(inputs[0].shape)\n",
    "        out = model(inputs[0])\n",
    "        # print(out)\n",
    "        y_pred = F.softmax(out,dim=1)\n",
    "        # print(y_pred[0])\n",
    "        our_predictions = torch.argmax(y_pred, dim=1)\n",
    "        print(our_predictions)\n",
    "        predicted_class = class_mapping[our_predictions.item()]\n",
    "        print(predicted_class)\n",
    "        assert(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "previous_prediction = None\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in single_match_loader:\n",
    "        current_input = inputs[0]  # Assuming the input tensor is in the first element of the list\n",
    "        if previous_prediction is not None:\n",
    "            # Update the input tensor with the previous prediction\n",
    "            current_input[0, -1, -1] = previous_prediction.item()\n",
    "\n",
    "        out = model(current_input)\n",
    "        y_pred = F.softmax(out, dim=1)\n",
    "        our_prediction = torch.argmax(y_pred, dim=1).item()\n",
    "\n",
    "        # Save the prediction and update the previous prediction for the next iteration\n",
    "        predictions.append(our_prediction)\n",
    "        previous_prediction = torch.tensor(our_prediction, dtype=torch.float32)\n",
    "\n",
    "# Now 'predictions' contains the predicted outcomes for each ball in the match\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "previous_prediction = None\n",
    "\n",
    "# Assuming features_tensor contains the entire match data\n",
    "for i in range(features_tensor.size(1)):  # Iterate through each ball in the match\n",
    "    current_input = features_tensor[:, i:i+1, :]\n",
    "\n",
    "    if previous_prediction is not None:\n",
    "        # Update the input tensor with the previous prediction\n",
    "        current_input[0, 0, -1] = previous_prediction.item()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        out = model(current_input)\n",
    "        y_pred = F.softmax(out, dim=1)\n",
    "        our_prediction = torch.argmax(y_pred, dim=1).item()\n",
    "\n",
    "    # Save the prediction and update the previous prediction for the next iteration\n",
    "    predictions.append(our_prediction)\n",
    "    previous_prediction = torch.tensor(our_prediction, dtype=torch.float32)\n",
    "\n",
    "# Now 'predictions' contains the predicted outcomes for each ball in the match\n",
    "print(predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_selected_match_df = selected_match_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_selected_match_df.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_selected_match_df['predicted_outcome'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_mapping = {\n",
    "    'delivery_type_0': 0,\n",
    "    'delivery_type_1': 1,\n",
    "    'delivery_type_2': 2,\n",
    "    'delivery_type_3': 3,\n",
    "    'delivery_type_4': 4,\n",
    "    'delivery_type_5': 5,\n",
    "    'delivery_type_6': 6,\n",
    "    'delivery_type_7': 7,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delivery_type_columns = ['delivery_type_0', 'delivery_type_1', 'delivery_type_2', 'delivery_type_3', 'delivery_type_4', 'delivery_type_5', 'delivery_type_6', 'delivery_type_7']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_selected_match_df['actual_outcome'] = (\n",
    "    predicted_selected_match_df[delivery_type_columns].apply(lambda row: sum(row[col] * column_mapping[col] for col in delivery_type_columns), axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_selected_match_df.drop('actual_outcome',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_selected_match_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_selected_match_df['ballnumber'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adding predicted current score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_selected_match_df['predicted_current_score'] = predicted_selected_match_df.groupby(['ID', 'innings'])['predicted_outcome'].cumsum()\n",
    "\n",
    "# Reset the index if needed\n",
    "predicted_selected_match_df = predicted_selected_match_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_selected_match_df['current_ball_number'] = predicted_selected_match_df.groupby('innings').cumcount()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample DataFrame with predicted_outcome and actual_outcome columns\n",
    "# Replace this with your actual DataFrame\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Scatter plot for predicted outcome\n",
    "plt.scatter(predicted_selected_match_df['overs'], predicted_selected_match_df['ballnumber'], c=predicted_selected_match_df['predicted_outcome'], marker='o', label='Predicted Outcome')\n",
    "\n",
    "# Scatter plot for actual outcome\n",
    "plt.scatter(predicted_selected_match_df['overs'], predicted_selected_match_df['ballnumber'], c=predicted_selected_match_df['actual_outcome'], marker='x', label='Actual Outcome')\n",
    "\n",
    "plt.xlabel('Over')\n",
    "plt.ylabel('Ball Number')\n",
    "plt.title('Predicted vs Actual Outcome')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample DataFrame with current_score, predicted_current_score, balls_left, and innings columns\n",
    "# Replace this with your actual DataFrame\n",
    "\n",
    "\n",
    "\n",
    "# Separate data for each inning\n",
    "inning1_data = predicted_selected_match_df[predicted_selected_match_df['innings'] == 1]\n",
    "inning2_data = predicted_selected_match_df[predicted_selected_match_df['innings'] == 2]\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 8), sharex=True)\n",
    "\n",
    "# Plot for Inning 1\n",
    "axes[0].plot(inning1_data['current_ball_number'], inning1_data['current_score'], marker='o', label='Actual Score')\n",
    "axes[0].plot(inning1_data['current_ball_number'], inning1_data['predicted_current_score'], marker='x', label='Predicted Score')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Inning 1 Actual vs Predicted Current Score')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot for Inning 2\n",
    "axes[1].plot(inning2_data['current_ball_number'], inning2_data['current_score'], marker='o', label='Actual Score')\n",
    "axes[1].plot(inning2_data['current_ball_number'], inning2_data['predicted_current_score'], marker='x', label='Predicted Score')\n",
    "axes[1].set_xlabel('Current Ball Number')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Inning 2 Actual vs Predicted Current Score')\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
